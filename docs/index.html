<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>tccp</title>
<link rel="stylesheet" href="style.css">
<link rel="icon" href="logo.png" type="image/png">
</head>
<body>
<img src="logo.png" alt="tccp" class="logo">
<h1>tccp - Tufts Cluster Command Prompt</h1>
<nav>
<a href="index.html">home</a>
<a href="install.html">install</a>
<a href="usage.html">usage</a>
<a href="commands.html">commands</a>
<a href="settings.html">settings</a>
<a href="architecture.html">how it works</a>
<a href="contact.html">contact</a>
</nav>

<div class="hero">
<h2>why this exists</h2>
<p>
Running code on an HPC cluster shouldn't feel different from running it
on your laptop. Open your editor, change a file, run it on a GPU. But
the usual workflow is: write a SLURM batch script, scp your code over,
submit, check the queue, scp results back. Or use a web UI with a clunky browser notebook. tccp replaces all of that with a
single CLI that makes the cluster feel <b>local</b>.
</p>
<p>
HPC clusters have real constraints. Your home directory is 30GB &mdash;
that fills up fast once you start using datasets and installing
packages. Scratch space is big but gets wiped. Figuring out what goes
where, cleaning up after yourself, and not blowing your quota is a whole
second job on top of the actual work.
</p>
<p>
tccp takes care of all of that for you! Just pretend you're local with JUMBO compute!
</p>
</div>

<h2>the experience</h2>
<p>
You work in your own editor, on your own machine. When you're ready to
run, you type <code>run train</code>. tccp syncs your code, makes sure
everything is set up on the cluster, and starts the job. Output streams
to your terminal for realtime interactive use. You can detach, go get coffee, come back
and reattach. If your WiFi dies, the job keeps running. Your results
download automatically when it finishes.
</p>
<p>
It feels like running locally, except the work is happening on cluster
hardware.
</p>

<h2>compared to the alternatives</h2>

<h3>vs. writing SLURM scripts by hand</h3>
<p>
The traditional way: write an sbatch script, scp your code, submit it,
check squeue, scp the results back, repeat. Every change means
re-uploading files. You manage your own containers, environments, and
storage. tccp does all of this for you in a single command.
</p>

<h3>vs. the On Demand web UI</h3>
<p>
The web UI gives you a Jupyter notebook in a browser or a remote desktop.
It works, but you're stuck in their editor and their environment. You
can't use your local tools, your dotfiles, your keybindings. tccp lets
you stay in your own setup and just sends the work to the cluster.
</p>

<h2>what you get</h2>
<ul>
<li>Edit locally, run remotely. Your editor, their GPUs.</li>
<li>One command from code change to running job</li>
<li>Jobs survive disconnects</li>
<li>Dependencies install automatically</li>
<li>Port forwarding for TensorBoard, Jupyter, etc.</li>
<li>Output downloads when the job finishes</li>
<li>Storage managed for you (no quota headaches)</li>
</ul>

<h2>quick start</h2>
<pre>
<span class="c"># install the binary (see install page)</span>

<span class="c"># save your credentials once</span>
$ tccp setup

<span class="c"># set up your project</span>
$ cd my-project
$ tccp register

<span class="c"># connect and run</span>
$ tccp
tccp> run train
</pre>

<p class="dim">v<span class="ver"></span> &mdash; built for the Tufts HPC cluster &mdash; <a href="https://github.com/Seth-Lupo/tccp">source on GitHub</a> &mdash; <a href="llms.txt">llms.txt</a></p>
<script src="version.js"></script>
</body>
</html>
